# Polish z≈Çoty, Romanian Leu, Singapore Dollar, Thai Baht, Turkish lira,
# United States dollar, South African Rand
out_marg_9 <- detect_cp_multi(data = as.matrix(data_er_mat[obs_9,]), n_iterations = 5000,
q = 0.25, k_0 = 1, nu_0 = length(obs_9),
phi_0 = diag(1, length(obs_9), length(obs_9)),
m_0 = rep(0, length(obs_9)), user_seed = seed)
order_9 <- mcclust.ext::minbinder.ext(psm = salso::psm(out_marg_9$orders[2000:5000,]))$cl
cp_9 <- cumsum(table(order_9))[-length(cumsum(table(order_9)))]
data_er$DATE[cp_9]
plot(data_er_mat[obs_9[1],], type= "l")
lines(data_er_mat[obs_9[2],])
lines(data_er_mat[obs_9[3],])
lines(data_er_mat[obs_9[4],])
lines(data_er_mat[obs_9[5],])
lines(data_er_mat[obs_9[6],])
lines(data_er_mat[obs_9[7],])
abline(v = cp_9)
for(i in 1:max(est_clust)){
cp <- get(paste0("cp_",i))
data <- as.numeric()
for(obs in get(paste0("obs_",i))){
data <- c(data,data_er_mat[obs,])
}
data_plot <- as_tibble(data) %>%
mutate(VALUE = value) %>%
select(VALUE)
data_plot <- data_plot %>%
mutate(COUNTRY =  sort(rep(exc_rates[which(est_clust == i)], length(data_er$DATE))))
data_plot <- data_plot %>%
mutate(DATE = rep(data_er$DATE,length(get(paste0("obs_",i)))))
p1 <- ggplot(data_plot) +
geom_line(aes(x = DATE, y = VALUE, color = COUNTRY),  linetype = 1) +
geom_vline(xintercept = unique(data_er$DATE[cp]), lty = 2) +
xlab("Date") +
ylab("Stock Price") +
labs(x = " ",
y = "y",
color = NULL) +
theme_minimal() +
theme(legend.position="top", legend.key.size = unit(.5, "cm"))
x <- data_er$DATE
b <- rep(0, length(data_er$DATE))
out_marg = get(paste0("out_marg_",i))
table_marg = table(as.numeric(unlist(apply(out_marg$orders, 1, function(x) cumsum(table(x))[-length(table(x))]))))
b[as.numeric(names(table_marg))] = as.numeric(table_marg)/3000
p2 <- ggplot(data.frame(x = x, y = b)) +
geom_bar(aes(x = x, y = y), stat="identity", width = 0.5, col = "black") +
theme_linedraw() +
theme(axis.title.x = element_blank(), axis.text.y = element_text(angle = 90)) +
scale_y_continuous(breaks = c(0,.5,1)) +
ylab("Prob.") +
xlab("Date") +
theme_minimal()
path = "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\exchange_rata_data\\plot"
png(filename = paste0(path,"\\TS_ER_cluster_",i,".png"), width = 5, height = 4, units = 'in', res = 300)
plot(ggarrange(p1, p2, nrow = 2, heights = c(2,1), common.legend = TRUE))
dev.off()
}
library("ggplot2")
library("ggpubr")
for(i in 1:max(est_clust)){
cp <- get(paste0("cp_",i))
data <- as.numeric()
for(obs in get(paste0("obs_",i))){
data <- c(data,data_er_mat[obs,])
}
data_plot <- as_tibble(data) %>%
mutate(VALUE = value) %>%
select(VALUE)
data_plot <- data_plot %>%
mutate(COUNTRY =  sort(rep(exc_rates[which(est_clust == i)], length(data_er$DATE))))
data_plot <- data_plot %>%
mutate(DATE = rep(data_er$DATE,length(get(paste0("obs_",i)))))
p1 <- ggplot(data_plot) +
geom_line(aes(x = DATE, y = VALUE, color = COUNTRY),  linetype = 1) +
geom_vline(xintercept = unique(data_er$DATE[cp]), lty = 2) +
xlab("Date") +
ylab("Stock Price") +
labs(x = " ",
y = "y",
color = NULL) +
theme_minimal() +
theme(legend.position="top", legend.key.size = unit(.5, "cm"))
x <- data_er$DATE
b <- rep(0, length(data_er$DATE))
out_marg = get(paste0("out_marg_",i))
table_marg = table(as.numeric(unlist(apply(out_marg$orders, 1, function(x) cumsum(table(x))[-length(table(x))]))))
b[as.numeric(names(table_marg))] = as.numeric(table_marg)/3000
p2 <- ggplot(data.frame(x = x, y = b)) +
geom_bar(aes(x = x, y = y), stat="identity", width = 0.5, col = "black") +
theme_linedraw() +
theme(axis.title.x = element_blank(), axis.text.y = element_text(angle = 90)) +
scale_y_continuous(breaks = c(0,.5,1)) +
ylab("Prob.") +
xlab("Date") +
theme_minimal()
path = "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\exchange_rata_data\\plot"
png(filename = paste0(path,"\\TS_ER_cluster_",i,".png"), width = 5, height = 4, units = 'in', res = 300)
plot(ggarrange(p1, p2, nrow = 2, heights = c(2,1), common.legend = TRUE))
dev.off()
}
lkl <- as.numeric()
for(i in 1:5000){
lkl_temp <- as.numeric()
for(j in 1:nrow(data_er_mat)){
lkl_temp[j] <- LogLikelihood_TS(data = t(as.matrix(data_er_mat[j,])), order = t(as.matrix(out_er$orders[(out_er$clust[i,j]+1),,i])), gamma_par = 0.1, a = 1, b = 1, c = 0.1)
}
lkl[i] <- sum(lkl_temp)
}
devtools::load_all(".")
lkl <- as.numeric()
for(i in 1:5000){
lkl_temp <- as.numeric()
for(j in 1:nrow(data_er_mat)){
lkl_temp[j] <- LogLikelihood_TS(data = t(as.matrix(data_er_mat[j,])), order = t(as.matrix(out_er$orders[(out_er$clust[i,j]+1),,i])), gamma_par = 0.1, a = 1, b = 1, c = 0.1)
}
lkl[i] <- sum(lkl_temp)
}
plot(lkl, type = "l")
df_likelihood_plot <- as.data.frame(cbind(1:length(lkl),lkl))
colnames(df_likelihood_plot) <- c("iteration","likelihood")
lkl_plot <- ggplot(data = df_likelihood_plot, aes(x = iteration, y = likelihood)) +
geom_line(colour = "black", lwd = 0.5) +
ylab("marginal log-likelihood") +
xlab("iteration") +
theme_bw()
path = "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\exchange_rata_data\\plot"
png(filename = paste0(path,"\\lkl_er.png"), width = 5, height = 2, units = 'in', res = 300)
lkl_plot
dev.off()
install.packages("ISLR2")
library(ISLR2)
data_house <- Boston
median(data_house$medv)
data_house[which(data_house$medv >= median(data_house$medv)),"medv01"] = 1
data_house[which(data_house$medv < median(data_house$medv)),"medv01"] = 0
data_house$medv01 <- as.factor(data_house$medv01)
boxplot(data_house$crim ~ data_house$medv01)
boxplot(data_house$rm ~ data_house$medv01)
mod.log1 <- glm(medv01 ~ crim + rm, family = binomial(link=logit),
data = data_house)
summary(mod.log1)
exp(coef(mod.log1)[2]) # Increasing the per capita crime rate by town
exp(coef(mod.log1)[3]) # Increasing the average number of rooms increases the
exp(coef(mod.log1)[2]*10)
mod.log2 <- glm(medv01 ~ crim + rm + age + lstat, family = binomial(link=logit), data = data_house)
summary(mod.log2)
anova(mod.log2, mod.log1,  test = "Chisq")
threshold = 0.5
y.hat <- ifelse(mod.log1$fitted.values < threshold, 0, 1)
errors <- (y.hat != data_house$crim01)
mis_rate <- sum(errors)/nrow(data_house); mis_rate
exp(coef(mod.log1)[2]*10)
lkl_plot <- ggplot(data = df_likelihood_plot, aes(x = iteration, y = likelihood)) +
geom_line(colour = "black", lwd = 0.5) +
ylab("log-likelihood") +
xlab("iteration") +
theme_bw()
path = "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\exchange_rata_data\\plot"
png(filename = paste0(path,"\\lkl_er.png"), width = 5, height = 2, units = 'in', res = 300)
lkl_plot
dev.off()
path = "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\exchange_rata_data\\plot"
png(filename = paste0(path,"\\lkl_er.png"), width = 6, height = 3, units = 'in', res = 300)
lkl_plot
dev.off()
library(ggpubr)
library(ggplot2)
library(tidyverse)
library(eurostat)
library(leaflet)
library(sf)
library(scales)
library(cowplot)
library(ggthemes)
library(urbnmapr)
library(BNPmix)
source("H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\Backup project\\Model-Based-Clustering-of-Time-Series\\10_import_real_data.R")
source("H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\Backup project\\Model-Based-Clustering-of-Time-Series\\3_functions_epydem.R")
states_to_remove_EU <- which(eu_states %in% c("Iceland", "Norway", "Liechtenstein"))
eu_states <- eu_states[-states_to_remove_EU]
Rcpp::sourceCpp(file = "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\Backup project\\Model-Based-Clustering-of-Time-Series\\main_code_fix.cpp")
path <- "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\Backup project\\Model-Based-Clustering-of-Time-Series"
load(paste0(path,"\\Real data EPI/est_model_EU_06062024_13.Rdata"))
lkl <- apply(est_model$llik, 1, function(x) sum(na.omit(x)))
plot(lkl, type = "l")
df_likelihood_plot <- as.data.frame(cbind(1:length(lkl),lkl))
colnames(df_likelihood_plot) <- c("iteration","likelihood")
df_likelihood_plot <- as.data.frame(cbind(1:length(lkl),lkl))
colnames(df_likelihood_plot) <- c("iteration","likelihood")
lkl_plot <- ggplot(data = df_likelihood_plot, aes(x = iteration, y = likelihood)) +
geom_line(colour = "black", lwd = 0.5) +
ylab("marginal log-likelihood") +
xlab("iteration") +
theme_bw()
png(filename = paste0("H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\Backup project\\Model-Based-Clustering-of-Time-Series\\Plot paper\\Plot\\likelihood_plot_EU_19032024_3",".png"), width = 6, height = 3, units = 'in', res = 300)
lkl_plot
dev.off()
load("H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\Backup project\\Model-Based-Clustering-of-Time-Series\\Real data EPI\\cluster_marginal_CP_EU_06062024_13.RData")
marginalCP_run <- save_finalpartitions
dates_run1 <- EU_dates[which(EU_dates == "2021-06-01"):which(EU_dates == "2022-09-30")]
cp1 <- cumsum(table(marginalCP_run[[1]]))
cp2 <- cumsum(table(marginalCP_run[[2]]))
cp3 <- cumsum(table(marginalCP_run[[3]]))
cp1 <- cp1[-length(cp1)]
cp2 <- cp2[-length(cp2)]
cp3 <- cp3[-length(cp3)]
dates_run1[cp1]
dates_run1[cp2]
dates_run1[cp3]
infection_times_COVID_EU <- lapply(infection_times_COVID_EU,
function(x)
x[which(EU_dates == "2021-06-01"):which(EU_dates == "2022-09-30")])
infection_times_COVID_EU <- infection_times_COVID_EU[-states_to_remove_EU]
dataEU <- matrix(0, nrow = length(infection_times_COVID_EU), ncol = length(infection_times_COVID_EU[[1]]))
for(i in 1:length(infection_times_COVID_EU)){
dataEU[i,] <- infection_times_COVID_EU[[i]]
}
dataEU_rolling <- matrix(0, nrow = length(infection_times_COVID_EU), ncol = length(infection_times_COVID_EU[[1]]))
for(i in 1:nrow(dataEU_rolling)){
dataEU[i, which(is.na(dataEU[i,]))] = 0
pool <- rep(1:length(dataEU_rolling[i,]), dataEU[i,])
pool_sampled <- sample(pool, 50000, replace = FALSE)
dataEU_rolling[i,as.numeric(names(table(pool_sampled)))] = table(pool_sampled)
dataEU_rolling[i,] <- round(zoo::rollmean(dataEU_rolling[i,], 7, fill = TRUE))
}
df_sf_plot <- data.frame(y = as.vector(sapply(1:27, function(x) 1 - cumsum(dataEU_rolling[x,]) / sum(dataEU_rolling[x,]))),
x = rep(1:487, 27),
obs = as.factor(rep(1:27, each = 487)),
Cluster = as.factor(rep(est_part, each = 487)))
out_er$clust
lkl <- as.numeric()
for(i in 1:20000){
lkl_temp <- as.numeric()
for(j in 1:nrow(data_er_mat)){
lkl_temp[j] <- LogLikelihood_TS(data = t(as.matrix(data_er_mat[j,])), order = t(as.matrix(out_er$orders[(out_er$clust[i,j]+1),,i])), gamma_par = 0.1, a = 1, b = 1, c = 0.1)
}
lkl[i] <- sum(lkl_temp)
}
plot(lkl, type = "l")
lkl_plot <- ggplot(data = df_likelihood_plot, aes(x = iteration, y = likelihood)) +
geom_line(colour = "black", lwd = 0.5) +
ylab("log-likelihood") +
xlab("iteration") +
theme_bw()
path = "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\exchange_rata_data\\plot"
png(filename = paste0(path,"\\lkl_er.png"), width = 6, height = 3, units = 'in', res = 300)
lkl_plot
dev.off()
lkl_plot
lkl_plot <- ggplot(data = df_likelihood_plot, aes(x = iteration, y = likelihood)) +
geom_line(colour = "black", lwd = 0.5) +
ylab("log-likelihood") +
xlab("iteration") +
theme_bw()
lkl_plot
plot(lkl, type = "l")
df_likelihood_plot <- as.data.frame(cbind(1:length(lkl),lkl))
colnames(df_likelihood_plot) <- c("iteration","likelihood")
lkl_plot <- ggplot(data = df_likelihood_plot, aes(x = iteration, y = likelihood)) +
geom_line(colour = "black", lwd = 0.5) +
ylab("log-likelihood") +
xlab("iteration") +
theme_bw()
lkl_plot
path = "H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\exchange_rata_data\\plot"
png(filename = paste0(path,"\\lkl_er.png"), width = 6, height = 3, units = 'in', res = 300)
lkl_plot
dev.off()
2+3 # somma
5^2 # potenze
exp(4) # esponenziale
risultato <- 2 + 3
risultato
risultato
Risultato
string <- "Hello World!"
string
?read.csv
temperature_data <- data.frame(read.csv("data_tmp_monthly.csv",header=TRUE))
# ESERCIZIO: impostare la working directory nel caso in cui non sia gia' la cartella
#            che contiene i file PLS
setwd("C:\\Users\\LUCA\\Downloads")
temperature_data <- data.frame(read.csv("data_tmp_monthly.csv",header=TRUE))
temperature_data
italy_data <- temperature_data[, c(1, 7)] # selezioniamo solo le variabili di nostro interesse
italy_data
usa_data_ts <- temperature_data[,c(1,12)]
usa_data_ts <- temperature_data[,c(1,10)]
str(italy_data) # codifica variabili
head(italy_data) # visualizzare le prime 6 osservazioni
italy_data[,1] <- seq(as.POSIXct("1970-01-01"), by = "month", length.out = nrow(italy_data))
italy_data_ts <- ts(italy_data$ITA, frequency = 12, start = c(1970, 1))
italy_data_ts
plot(italy_data_ts, type="l", pch=19,
main="Temperatura media dal 1970 al 2023 in Italia", ylab="temperatura media")
plot(italy_data_ts, type="l", pch=19,
main="Temperatura media dal 1970 al 2023 in Italia", ylab="temperatura media")
plot(italy_data_ts, type="l", pch=19,
main="Temperatura media dal 1970 al 2023 in Italia", ylab="temperatura media")
plot(italy_data_ts, type="l", pch=19,
main="Temperatura media dal 1970 al 2023 in Italia", ylab="temperatura media")
library(ISLR2)
library(survival)
?veteran
data <- veteran
fit.posres <- survfit(Surv(time, status) ~ 1, data = veteran)
survdiff(Surv(time,status) ~ celltype, data = veteran)
prova_1 <- survdiff(Surv(time,status) ~ celltype, data = veteran)
prova_2 <- survfit(Surv(time,status) ~ celltype, data = veteran)
prova_1
prova_2
autoplot(prova_2)
mcmc_chain <- BNPmix::clean_partition(out_er$clust[5000:15000,])
est_clust
load("H:\\Il mio Drive\\Dottorato\\Progetti\\Model Based Clustering of TS\\exchange_rata_data\\results_er_24012025.Rdata")
exc_rates <- c("EUR_AUD","EUR_BRL","EUR_CAD","EUR_CHF",
"EUR_CNY","EUR_CZK", "EUR_DKK", "EUR_GBP", "EUR_HKD", "EUR_HUF",
"EUR_IDR", "EUR_ILS", "EUR_INR", "EUR_ISK", "EUR_JPY", "EUR_KRW",
"EUR_MXN","EUR_MYR","EUR_NOK","EUR_NZD","EUR_PHP","EUR_PLN",
"EUR_RON", "EUR_SEK","EUR_SGD","EUR_THB","EUR_TRY","EUR_USD","EUR_ZAR")
mcmc_chain <- BNPmix::clean_partition(out_er$clust[5000:15000,])
est_clust <- mcclust.ext::minbinder.ext(psm = salso::psm(mcmc_chain),
cls.draw = mcmc_chain, method = "draws")$cl + 1
est_clust
prova_salso <- salso::salso(x = mcmc_chain, loss = "binder", maxNClusters = 7);prova_salso;table(prova_salso)
prova_salso <- salso::salso(x = mcmc_chain, loss = "binder", maxNClusters = 8);prova_salso;table(prova_salso)
exc_rates[which(est_clust == 1)]
obs_7 <- which(est_clust == 7)
obs_7
obs_8
obs_8 <- which(est_clust == 8)
est_clust[c(obs_7,obs_8)]
prova_salso[c(obs_7,obs_8)]
prova_salso <- salso::salso(x = mcmc_chain, loss = "binder", maxNClusters = 7);prova_salso;table(prova_salso)
prova_salso[c(obs_7,obs_8)]
ggsurvplot(prova_1,
risk.table = TRUE, # Add risk table
risk.table.col = "strata", # Change risk table color by groups
surv.median.line = "hv", # Specify median survival
ggtheme = theme_bw(), # Change ggplot2 theme
break.time.by=90,
title="Kaplan-Meier Curve for Lung Cancer Survival")
library(ggsurvplot)
library(survival)
library(survminer)
ggsurvplot(prova_1,
risk.table = TRUE, # Add risk table
risk.table.col = "strata", # Change risk table color by groups
surv.median.line = "hv", # Specify median survival
ggtheme = theme_bw(), # Change ggplot2 theme
break.time.by=90,
title="Kaplan-Meier Curve for Lung Cancer Survival")
ggsurvplot(prova_1,
risk.table = TRUE, # Add risk table
risk.table.col = "strata", # Change risk table color by groups
surv.median.line = "hv", # Specify median survival
ggtheme = theme_bw(), # Change ggplot2 theme
break.time.by=90,
title="Kaplan-Meier Curve for Lung Cancer Survival")
library(survival)
library(survminer)
ggsurvplot(prova_1)
ggsurvplot(prova_2)
surv(prova_2)
prova_2 <- survfit(Surv(time,status) ~ celltype, data = veteran)
prova_2
prova_1 <- survdiff(Surv(time,status) ~ celltype, data = veteran)
prova_1
veteran$age
table(veteran$age)
prova_1 <- survdiff(Surv(time,status) ~ celltype, data = veteran)
prova_1
veteran$age_binary <- ifelse(veteran$age < 60, "<60", ">=")
veteran$age_binary
veteran$age_binary <- ifelse(veteran$age < 60, "<60", ">=60")
veteran$age_binary
prova_2 <- survdiff(Surv(time,status) ~ age_binary, data = veteran)
prova_2
plot(prova_2)
prova_2_fit <- survfit(Surv(time,status) ~ age_binary, data = veteran)
plot(prova_2_fit)
veteran$age_binary <- ifelse(veteran$age < 65, "<65", ">=65")
prova_2 <- survdiff(Surv(time,status) ~ age_binary, data = veteran)
prova_2_fit <- survfit(Surv(time,status) ~ age_binary, data = veteran)
plot(prova_2_fit)
prova_2_fit
prova_2
veteran$age_binary <- ifelse(veteran$age < 70, "<70", ">=70")
prova_2 <- survdiff(Surv(time,status) ~ age_binary, data = veteran)
prova_2
veteran$age_binary <- ifelse(veteran$age < 60, "<60", ">=60")
prova_2 <- survdiff(Surv(time,status) ~ age_binary, data = veteran)
prova_2
surv_1 <- survdiff(Surv(time,status) ~ celltype, data = veteran); surv_1
veteran$age_binary <- ifelse(veteran$age <= 60, "<=60", ">60")
surv_2 <- survdiff(Surv(time,status) ~ age_binary, data = veteran); surv_2 # significant
surv_1
survdiff(Surv(time, status) ~ sex, data = lung)
surv_1
veteran
surv_2
HR <- (54/62)/(74/66)
HR
HR <- (6/2.62)/(3/6.38)
HR
survdiff(Surv(time, status) ~ agecat70, data=lung)
survdiff(Surv(time, status) ~ sex, data = lung)
# Therefore, the death hazard ratio of males vs females is:
hazard_ratio <- (112/91.6)/(53/73.4)
surv_2
(74/66)/(54/62)
(54/62)/(74/66) # "<=60" vs ">60"
(74/66)/(54/62) # ">60" vs "<=60"
veteran
?time
?veteran
devtools::load_all(".")
?detect_cp_uni
data_vec <- as.numeric(c(rnorm(50,0,0.1), rnorm(50,1,0.25)))
out <- detect_cp_uni(data = data_vec,
n_iterations = 2500,
q = 0.25,
phi = 0.1, a = 1, b = 1, c = 0.1)
remove.packages("BayesCPs")
devtools::load_all(".")
data_vec <- as.numeric(c(rnorm(50,0,0.1), rnorm(50,1,0.25)))
out <- detect_cp_uni(data = data_vec,
n_iterations = 2500,
q = 0.25,
phi = 0.1, a = 1, b = 1, c = 0.1)
data_vec <- as.numeric(c(rnorm(50,0,0.1), rnorm(50,1,0.25)))
out <- detect_cp_uni(data = data_vec,
n_iterations = 2500,
q = 0.25,
phi = 0.1, a = 1, b = 1, c = 0.1)
devtools::load_all(".")
data_vec <- as.numeric(c(rnorm(50,0,0.1), rnorm(50,1,0.25)))
out <- detect_cp_uni(data = data_vec,
n_iterations = 2500,
q = 0.25,
phi = 0.1, a = 1, b = 1, c = 0.1)
detect_cp_uni
out$time
?detect_cp_multi
data_mat <- matrix(NA, nrow = 3, ncol = 100)
data_mat[1,] <- as.numeric(c(rnorm(50,0,0.100), rnorm(50,1,0.250)))
data_mat[2,] <- as.numeric(c(rnorm(50,0,0.125), rnorm(50,1,0.225)))
data_mat[3,] <- as.numeric(c(rnorm(50,0,0.175), rnorm(50,1,0.280)))
out <- detect_cp_multi(data = data_mat,
n_iterations = 2500,
q = 0.25,k_0 = 0.25, nu_0 = 4, phi_0 = diag(1,3,3), m_0 = rep(0,3),
par_theta_c = 2, par_theta_d = 0.2, prior_var_gamma = 0.1)
out$time
devtools::load_all(".")
data_vec <- as.numeric(c(rnorm(50,0,0.1), rnorm(50,1,0.25)))
out <- detect_cp_uni(data = data_vec,
n_iterations = 2500,
q = 0.25,
phi = 0.1, a = 1, b = 1, c = 0.1)
out$time
?cluster_cp_epi
data_mat <- matrix(NA, nrow = 5, ncol = 50)
betas <- list(c(rep(0.45, 25),rep(0.14,25)),
c(rep(0.55, 25),rep(0.11,25)),
c(rep(0.50, 25),rep(0.12,25)),
c(rep(0.52, 10),rep(0.15,40)),
c(rep(0.53, 10),rep(0.13,40)))
inf_times <- list()
for(i in 1:5){
inf_times[[i]] <- sim_epi_data(10000, 10, 50, betas[[i]], 1/8)
vec <- rep(0,50)
names(vec) <- as.character(1:50)
for(j in 1:50){
if(as.character(j) %in% names(table(floor(inf_times[[i]])))){
vec[j] = table(floor(inf_times[[i]]))[which(names(table(floor(inf_times[[i]]))) == j)]
}
}
data_mat[i,] <- vec
}
out <- cluster_cp_epi(data = data_mat, n_iterations = 5000, M = 500, B = 1000, L = 1)
out$time
?cluster_cp_uni
data_mat <- matrix(NA, nrow = 5, ncol = 100)
data_mat[1,] <- as.numeric(c(rnorm(50,0,0.100), rnorm(50,1,0.250)))
data_mat[2,] <- as.numeric(c(rnorm(50,0,0.125), rnorm(50,1,0.225)))
data_mat[3,] <- as.numeric(c(rnorm(50,0,0.175), rnorm(50,1,0.280)))
data_mat[4,] <- as.numeric(c(rnorm(25,0,0.135), rnorm(75,1,0.225)))
data_mat[5,] <- as.numeric(c(rnorm(25,0,0.155), rnorm(75,1,0.280)))
out <- cluster_cp_uni(data = data_mat, n_iterations = 5000, B = 1000, L = 1, gamma = 0.5)
out$time
?cluster_cp_multi
data_array <- array(data = NA, dim = c(3,100,5))
data_array[1,,1] <- as.numeric(c(rnorm(50,0,0.100), rnorm(50,1,0.250)))
data_array[2,,1] <- as.numeric(c(rnorm(50,0,0.100), rnorm(50,1,0.250)))
data_array[3,,1] <- as.numeric(c(rnorm(50,0,0.100), rnorm(50,1,0.250)))
data_array[1,,2] <- as.numeric(c(rnorm(50,0,0.100), rnorm(50,1,0.250)))
data_array[2,,2] <- as.numeric(c(rnorm(50,0,0.100), rnorm(50,1,0.250)))
data_array[3,,2] <- as.numeric(c(rnorm(50,0,0.100), rnorm(50,1,0.250)))
data_array[1,,3] <- as.numeric(c(rnorm(50,0,0.175), rnorm(50,1,0.280)))
data_array[2,,3] <- as.numeric(c(rnorm(50,0,0.175), rnorm(50,1,0.280)))
data_array[3,,3] <- as.numeric(c(rnorm(50,0,0.175), rnorm(50,1,0.280)))
data_array[1,,4] <- as.numeric(c(rnorm(25,0,0.135), rnorm(75,1,0.225)))
data_array[2,,4] <- as.numeric(c(rnorm(25,0,0.135), rnorm(75,1,0.225)))
data_array[3,,4] <- as.numeric(c(rnorm(25,0,0.135), rnorm(75,1,0.225)))
data_array[1,,5] <- as.numeric(c(rnorm(25,0,0.155), rnorm(75,1,0.280)))
data_array[2,,5] <- as.numeric(c(rnorm(25,0,0.155), rnorm(75,1,0.280)))
data_array[3,,5] <- as.numeric(c(rnorm(25,0,0.155), rnorm(75,1,0.280)))
out <- cluster_cp_multi(data = data_array, n_iterations = 5000, B = 1000, L = 1,
gamma = 0.1, k_0 = 0.25, nu_0 = 5, phi_0 = diag(0.1,3,3), m_0 = rep(0,3))
out$time
git config --global user.email "danese.luca1@gmail.com"
